{
  "metadata": {
    "name": "data-analytics",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nfile_path \u003d \u0027/user/tw2770_nyu_edu/final-project/lyrics-emotion-rating\u0027\n\ndf \u003d spark.read.parquet(file_path)\n\ndf.show(20)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Calculate the distribution of `rating` column"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nrating_distribution \u003d df.groupBy(\"rating\").agg(\n    count(\"*\").alias(\"count\")\n)\n\n# Show the result\nrating_distribution.orderBy(\"rating\").show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Calculate the distribution among the emotions"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nfrom pyspark.sql.functions import col, round, avg, min, max, count, row_number\nfrom pyspark.sql import Window\n\nemotion_counts \u003d df.groupBy(\"emotion\").count()\n\n# Calculate total number of records\ntotal \u003d df.count()\n\n# Add a \u0027percentage\u0027 column\nemotion_distribution \u003d emotion_counts.withColumn(\n    \"percentage\",\n    round((col(\"count\") / total) * 100, 2)\n).orderBy(col(\"count\").desc())\n\n# Show the distribution with percentages\nemotion_distribution.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Analyze the relationship between `emotion` and `rating`"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nemotion_rating_stats \u003d df.groupBy(\"emotion\").agg(\n    avg(\"rating\").alias(\"average\"),\n    min(\"rating\").alias(\"min\"),\n    max(\"rating\").alias(\"max\")\n)\n\nemotion_rating_stats.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\n# Group by rating and emotion, then count the occurrences\nemotion_rating_distribution \u003d df.groupBy(\"rating\", \"emotion\").agg(\n    count(\"*\").alias(\"count\")\n).orderBy(\"rating\", \"emotion\")\n\nemotion_rating_distribution.show(60)"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nkeyword_path \u003d \u0027/user/tw2770_nyu_edu/final-project/lyrics-emotion-keyword-rating\u0027\nkeywords_df \u003d spark.read.parquet(keyword_path)\nkeywords_df.show(100)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Calculate occurences for each of the keyword"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nkeyword_count \u003d keywords_df.groupBy(\"keyword\").agg(\n    count(\"*\").alias(\"total_count\")\n)\n\nkeyword_count.orderBy(col(\"total_count\").desc()).show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Top 10 keywords"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ntop_10_keywords \u003d keyword_count.orderBy(col(\"total_count\").desc()).limit(10).drop(\"total_count\")\n\ntop_10_keywords.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Calculate the distribution among the emotions for each keyword"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nkeyword_emotion_count \u003d keywords_df.groupBy(\"keyword\", \"emotion\").agg(\n    count(\"*\").alias(\"count\")\n)\n\nkeyword_emotion_count.orderBy(\"keyword\", col(\"count\").desc()).show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Show the distribution among the emotions of the top 10 keywords"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\n# Filter keyword_emotion_count for only the top 10 keywords\ntop_10_keyword_emotion_count \u003d keyword_emotion_count.join(\n    top_10_keywords, \"keyword\", \"inner\"\n)\n\n# Show the result\ntop_10_keyword_emotion_count.orderBy(\"keyword\").show(60)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Calculate the keyword-rating matrix\n"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql.functions import col, count, sum, round\n\n# Group by keyword and rating to count occurrences\nkeyword_rating_counts \u003d keywords_df.groupBy(\"keyword\", \"rating\").agg(count(\"*\").alias(\"count\"))\n\n# Sum counts by keyword to calculate total counts per keyword\nkeyword_totals \u003d keyword_rating_counts.groupBy(\"keyword\").agg(sum(\"count\").alias(\"total_count\"))\n\n# Join keyword_rating_counts with keyword_totals to calculate percentages\nkeyword_rating_percentages \u003d keyword_rating_counts.join(\n    keyword_totals, on\u003d\"keyword\"\n).withColumn(\n    \"percentage\", round((col(\"count\") / col(\"total_count\")), 2)\n)\n\n# Pivot table to create matrix\nkeyword_rating_matrix \u003d keyword_rating_percentages.groupBy(\"keyword\").pivot(\"rating\").agg(\n    sum(\"percentage\")\n).fillna(0)\n\n# Show the resulting matrix\nkeyword_rating_matrix.show(45)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Calculate the keyword-genre matrix\n"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# Group by keyword and tag to count occurrences\nkeyword_tag_counts \u003d keywords_df.groupBy(\"keyword\", \"tag\").agg(count(\"*\").alias(\"count\"))\n\n# Calculate total counts per keyword\nkeyword_totals \u003d keyword_tag_counts.groupBy(\"keyword\").agg(sum(\"count\").alias(\"total_count\"))\n\n# Join to calculate percentages\nkeyword_tag_percentages \u003d keyword_tag_counts.join(\n    keyword_totals, on\u003d\"keyword\"\n).withColumn(\n    \"percentage\", round((col(\"count\") / col(\"total_count\")), 2)\n)\n\n# Pivot table to create matrix\nkeyword_tag_matrix \u003d keyword_tag_percentages.groupBy(\"keyword\").pivot(\"tag\").agg(\n    sum(\"percentage\")\n).fillna(0)\n\n# Show the resulting matrix\nkeyword_tag_matrix.show(45)"
    }
  ]
}